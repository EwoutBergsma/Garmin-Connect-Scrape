{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2da19b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44562d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse_html_files(directory):\n",
    "    \"\"\"\n",
    "    Load and parse (using BeautifulSoep) all HTML files in the specified directory.\n",
    "    Args:\n",
    "        directory (str): The path to the directory containing HTML files.\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - html_files (list): A list of paths to the HTML files found.\n",
    "            - soups (list): A list of BeautifulSoup objects representing the parsed HTML files.\n",
    "    \"\"\"\n",
    "    html_files = glob.glob(os.path.join(directory, '*.html'))\n",
    "    if not html_files:\n",
    "        raise FileNotFoundError(f\"No HTML files found in directory: {directory}\")\n",
    "    \n",
    "    print(f\"Found {len(html_files)} HTML files in directory: {directory}\")\n",
    "\n",
    "    soups = []\n",
    "    # Open each HTML file\n",
    "    for file_path in html_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                soups.append(BeautifulSoup(content, 'html.parser'))\n",
    "                print(f\"Processed file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    return html_files, soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c092b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 HTML files in directory: html\n",
      "Processed file: html\\09_04_2025.html\n",
      "Processed file: html\\10_04_2025.html\n",
      "Processed file: html\\13_04_2025.html\n",
      "Start time: 23:51:00, End time: 08:24:00\n",
      "Start time: 00:33:00, End time: 08:24:00\n",
      "Start time: 22:29:00, End time: 07:42:00\n"
     ]
    }
   ],
   "source": [
    "def find_begin_and_end_timestamps(soup):\n",
    "    \"\"\"\n",
    "    Find the first and last timestamps of the graph (see README.md) in the HTML soup object.\n",
    "    Args:\n",
    "        soup: The BeautifulSoup object containing the HTML content.\n",
    "    Returns:\n",
    "        tuple: A tuple containing the first and last timestamps as datetime.datetime objects.\n",
    "    \"\"\"\n",
    "\n",
    "    # Example of div with start and end time: <div class=\"    flexboxgrid_colXs__2BUM1      flexboxgrid_collapse__v6Hdm  \"><span>12:33 AM</span><span class=\"SleepTimeEditors_pencilIcon__ejpUi\"><i class=\"icon-pencil undefined\" style=\"font-size: 14px;\"></i></span></div>\n",
    "    time_elements = soup.find_all(\"div\", class_=\"flexboxgrid_colXs__2BUM1\")\n",
    "    time_elements = [time_element.text.strip() for time_element in time_elements]\n",
    "    # Convert list of text strings (e.g. \"12:33 AM\") to list of datetime.datetime objects\n",
    "    time_elements = [datetime.strptime(time_element, \"%I:%M %p\") for time_element in time_elements]  # Convert text string (e.g. \"12:33 AM\") to datetime.datetime object\n",
    "\n",
    "    # Check if start time is in the evening and the end time is in the morning, this fixes the circular issue (going to bed at 22:00 and waking up at 07:00 would result in timedelta of 15 hours)\n",
    "    if time_elements[0].hour >= 12 and time_elements[1].hour < 12:\n",
    "        # If the first time is in the evening and the last time is in the morning, we assume the last time is on the next day\n",
    "        time_elements[1] = time_elements[1] + timedelta(days=1)\n",
    "\n",
    "    # Check if we have exactly two time elements (start and stop time)\n",
    "    if len(time_elements) != 2:\n",
    "        raise ValueError(f\"Found {len(time_elements)} time elements, expected exactly two (i.e. start and stop time).\")\n",
    "    \n",
    "    return time_elements\n",
    "\n",
    "# Test the functions thusfar\n",
    "_, soups = load_and_parse_html_files('html')\n",
    "for soup in soups:\n",
    "    start_time, end_time = find_begin_and_end_timestamps(soup)\n",
    "    print(f\"Start time: {start_time.time()}, End time: {end_time.time()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f13dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 1900-01-01 23:51:00, End time: 1900-01-02 08:24:00, Time delta: 8:33:00\n",
      "[datetime.datetime(1900, 1, 1, 23, 51), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 1, 23, 59), 'Deep Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 0, 45), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 0, 58), 'Deep Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 1, 15), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 1, 24), 'Deep Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 1, 32), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 1, 49), 'REM Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 2, 8), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 2, 22), 'REM Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 2, 23), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 2, 24), 'REM Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 2, 25), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 3, 49), 'Deep Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 4, 1), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 4, 16), 'REM Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 5, 10), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 6, 16), 'Unmeasurable']\n",
      "[datetime.datetime(1900, 1, 2, 6, 36), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 6, 47), 'REM Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 7, 1), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 7, 34), 'Deep Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 7, 44), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 7, 45), 'Awake']\n",
      "[datetime.datetime(1900, 1, 2, 7, 46), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 8, 1), 'REM Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 8, 13), 'Light Sleep']\n",
      "[datetime.datetime(1900, 1, 2, 8, 24), 'End of Sleep']\n"
     ]
    }
   ],
   "source": [
    "def get_timestamps_for_each_sleepcycle(soup, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Get the timestamps for each sleep cycle from the parsed HTML soups. This is done by assessing the relative locations of the coloured rectangles in the graph. Returns start and end times of each sleep cycle, including which sleep cycle label.\n",
    "    Args:\n",
    "        soup: The BeautifulSoup object containing the HTML content.\n",
    "        start_time: datetime.time: The start time of the sleep.\n",
    "        end_time: datetime.time: The end time of the sleep.\n",
    "    Returns:\n",
    "        list: A list of tuples, each containing the start and end timestamps and label of a sleep cycle.\n",
    "    \"\"\"\n",
    "    # The chart is dynamic, based on the size of the screen, so lets use the vertical dashed lines to find the (relative) horizontal start and end position of the graph.\n",
    "    # These lines are found in a <g> element with class=\"highcharts-plot-lines-5\", with two <path> elements inside with class=\"highcharts-plot-line \", each with a \"d\" attribute containing the coordinates of the line.\n",
    "    vertical_lines = soup.find(\"g\", class_=\"highcharts-plot-lines-5\")    \n",
    "    vertical_lines = vertical_lines.find_all(\"path\", class_=\"highcharts-plot-line\")\n",
    "    if not len(vertical_lines) == 2:\n",
    "        raise ValueError(f\"Expected exactly two vertical lines in the graph, found: {len(vertical_lines)}\")\n",
    "    # The first line contains the relative start time, the second line contains the relative end time.\n",
    "    relative_start_time = float(vertical_lines[0].get(\"d\").split()[-2])\n",
    "    relative_end_time = float(vertical_lines[1].get(\"d\").split()[-2])\n",
    "\n",
    "    # Make start time 0, and correct the end time accordingly\n",
    "    relative_end_time = relative_end_time - relative_start_time\n",
    "    relative_start_time = relative_start_time - relative_start_time\n",
    "\n",
    "    # The rectangles of a graph are <g></g> elements, each with multiple <path></path> elements inside. Finding the <g></g> elements using class names such as: [\"\"highcharts-series highcharts-series-0 highcharts-area-series\", \"highcharts-series highcharts-series-1 highcharts-area-series\"]\n",
    "    pattern = re.compile(r\"highcharts-series highcharts-series-\\d+ highcharts-area-series\")\n",
    "    rectangles = soup.find_all(\"g\", class_=pattern)\n",
    "    if not rectangles:\n",
    "        raise ValueError(\"No rectangles found in the graph. Please check the HTML structure or class names.\")\n",
    "    \n",
    "    # print(len(rectangles), \"rectangles found in the graph.\")\n",
    "\n",
    "    # Each of these <g></g> elements, in its first child element (<path></path>), the \"d\" attribute contains the coordinates of the rectangle in the graph. The number after the first L is the starting x coordinate of the rectangle, and the number after the second L is the ending x coordinate of the rectangle.\n",
    "    # Moreover, the colour (fill) of first child element (<path></path>) indicates the type of sleep cycle (e.g. #3b97f3 = light, #1976d2 = deep, #d42fc2 = REM, #e55ecb = Awake, transparant = Unmeasurable).\n",
    "    sleep_labels = {\n",
    "        \"#3b97f3\": \"Light Sleep\",\n",
    "        \"#1976d2\": \"Deep Sleep\",\n",
    "        \"#d42fc2\": \"REM Sleep\",\n",
    "        \"#e55ecb\": \"Awake\",\n",
    "        \"transparent\": \"Unmeasurable\"\n",
    "    }\n",
    "\n",
    "    sleep_cycles = []\n",
    "    for rectangle in rectangles:\n",
    "        path = rectangle.find(\"path\")  # Contains the coordinates and fill colour of the rectangle\n",
    "        path_d = path.get(\"d\")  # The \"d\" attribute contains the coordinates of the rectangle\n",
    "\n",
    "        # Extract the x coordinates from the \"d\" attribute, by first splitting the string into tokens\n",
    "        tokens = path_d.split()\n",
    "\n",
    "        # Find the first occurance of \"L\" , the number (now token) after it contains start coordinate\n",
    "        start_coordinate = float(tokens[tokens.index('L') + 1])\n",
    "\n",
    "        # Get the sleep cycle label based on the fill colour\n",
    "        path_fill = sleep_labels[path.get(\"fill\")]\n",
    "\n",
    "        sleep_cycles.append([start_coordinate, path_fill])\n",
    "\n",
    "    # Convert the relative start and end times to absolute times\n",
    "    # First we normalize the starting times\n",
    "    sleep_cycles = [[sleep_cycle[0]/relative_end_time, sleep_cycle[1]] for sleep_cycle in sleep_cycles]\n",
    "    # Then calculate the timedelta from the provided start and end times\n",
    "    timedelta = end_time - start_time\n",
    "    # print(end_time, start_time, timedelta)\n",
    "    # Add the weighted timedelta to the start time \n",
    "    sleep_cycles = [[(start_time + timedelta * sleep_cycle[0]), sleep_cycle[1]] for sleep_cycle in sleep_cycles]\n",
    "\n",
    "    sleep_cycles.append([end_time, \"End of Sleep\"])  # Append the end time of the sleep\n",
    "\n",
    "    return sleep_cycles\n",
    "\n",
    "# Test\n",
    "for soup in soups[:1]:\n",
    "    start_time, end_time = find_begin_and_end_timestamps(soup)\n",
    "    print(f\"Start time: {start_time}, End time: {end_time}, Time delta: {end_time - start_time}\")\n",
    "    sleep_cycles = get_timestamps_for_each_sleepcycle(soup, start_time, end_time)\n",
    "\n",
    "    for sleep_cycle in sleep_cycles:\n",
    "        print(sleep_cycle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2fc4bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sleep cycles to a CSV file\n",
    "def save_sleep_cycles_to_csv(sleep_cycles, output_file, directory='csv'):\n",
    "    \"\"\"\n",
    "    Save the sleep cycles to a CSV file.\n",
    "    Args:\n",
    "        sleep_cycles (list): A list of tuples containing the start and end timestamps and label of each sleep cycle.\n",
    "        output_file (str): The path to the output CSV file.\n",
    "        directory (str): The directory where the CSV file will be saved.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(directory, output_file)\n",
    "    os.makedirs(directory, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Start Time', 'Sleep Cycle'])  # Write header\n",
    "        for sleep_cycle in sleep_cycles:\n",
    "            writer.writerow([sleep_cycle[0], sleep_cycle[1]])\n",
    "    print(f\"Saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "14098cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 HTML files in directory: html\n",
      "Processed file: html\\09_04_2025.html\n",
      "Processed file: html\\10_04_2025.html\n",
      "Processed file: html\\13_04_2025.html\n",
      "Start time: 1900-01-01 23:51:00, End time: 1900-01-02 08:24:00, Time delta: 8:33:00\n",
      "Saved to csv\\09_04_2025.csv\n",
      "Start time: 1900-01-01 00:33:00, End time: 1900-01-01 08:24:00, Time delta: 7:51:00\n",
      "Saved to csv\\10_04_2025.csv\n",
      "Start time: 1900-01-01 22:29:00, End time: 1900-01-02 07:42:00, Time delta: 9:13:00\n",
      "Saved to csv\\13_04_2025.csv\n"
     ]
    }
   ],
   "source": [
    "# The full thing\n",
    "file_names, soups = load_and_parse_html_files('html')\n",
    "for soup, file_name in zip(soups, file_names):\n",
    "    start_time, end_time = find_begin_and_end_timestamps(soup)\n",
    "    print(f\"Start time: {start_time}, End time: {end_time}, Time delta: {end_time - start_time}\")\n",
    "    sleep_cycles = get_timestamps_for_each_sleepcycle(soup, start_time, end_time)\n",
    "    save_sleep_cycles_to_csv(sleep_cycles, os.path.basename(file_name).replace('.html', '.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
