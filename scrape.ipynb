{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da19b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44562d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse_html_files(directory):\n",
    "    \"\"\"\n",
    "    Load and parse (using BeautifulSoep) all HTML files in the specified directory.\n",
    "    Args:\n",
    "        directory (str): The path to the directory containing HTML files.\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - html_files (list): A list of paths to the HTML files found.\n",
    "            - soups (list): A list of BeautifulSoup objects representing the parsed HTML files.\n",
    "    \"\"\"\n",
    "    html_files = glob.glob(os.path.join(directory, '*.html'))\n",
    "    if not html_files:\n",
    "        raise FileNotFoundError(f\"No HTML files found in directory: {directory}\")\n",
    "    \n",
    "    print(f\"Found {len(html_files)} HTML files in directory: {directory}\")\n",
    "\n",
    "    soups = []\n",
    "    # Open each HTML file\n",
    "    for file_path in html_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                soups.append(BeautifulSoup(content, 'html.parser'))\n",
    "                print(f\"Processed file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    return html_files, soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c092b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 HTML files in directory: html\n",
      "Processed file: html\\09_04_2025.html\n",
      "Processed file: html\\10_04_2025.html\n",
      "Processed file: html\\13_04_2025.html\n",
      "Start time: 23:51:00, End time: 08:24:00\n",
      "Start time: 00:33:00, End time: 08:24:00\n",
      "Start time: 22:29:00, End time: 07:42:00\n"
     ]
    }
   ],
   "source": [
    "def find_begin_and_end_timestamps(soup):\n",
    "    \"\"\"\n",
    "    Find the first and last timestamps of the graph (see README.md) in the HTML soup object.\n",
    "    Args:\n",
    "        soup: The BeautifulSoup object containing the HTML content.\n",
    "    Returns:\n",
    "        tuple: A tuple containing the first and last timestamps as datetime.datetime objects.\n",
    "    \"\"\"\n",
    "    # Find starting day <span> element with class \"NavigationComponent_datePickerBoxContainer__q-LPO\", then extracting the text from its last <span> child element\n",
    "    start_day = soup.find(\"span\", class_=\"NavigationComponent_datePickerBoxContainer__q-LPO\").find_all(\"span\")[-1].text.strip()\n",
    "    # Convert the start day text (e.g. Apr 9, 2022) to a datetime object\n",
    "    start_day = datetime.strptime(start_day, \"%b %d, %Y\")\n",
    "\n",
    "    # Now find the time elements in the HTML soup\n",
    "    # Example of div with start and end time: <div class=\"    flexboxgrid_colXs__2BUM1      flexboxgrid_collapse__v6Hdm  \"><span>12:33 AM</span><span class=\"SleepTimeEditors_pencilIcon__ejpUi\"><i class=\"icon-pencil undefined\" style=\"font-size: 14px;\"></i></span></div>\n",
    "    time_elements = soup.find_all(\"div\", class_=\"flexboxgrid_colXs__2BUM1\")\n",
    "    time_elements = [time_element.text.strip() for time_element in time_elements]\n",
    "    # Convert list of text strings (e.g. \"12:33 AM\") to list of datetime.datetime objects\n",
    "    time_elements = [datetime.strptime(time_element, \"%I:%M %p\").time() for time_element in time_elements]  # Convert text string (e.g. \"12:33 AM\") to datetime.datetime object\n",
    "\n",
    "    # Combine the start day with the time elements to create complete datetime.datetime objects\n",
    "    datetimes = [datetime.combine(start_day, time_element) for time_element in time_elements]\n",
    "\n",
    "    # Check if start time is in the evening and the end time is in the morning, this fixes the circular issue (going to bed at 22:00 and waking up at 07:00 would result in timedelta of 15 hours)\n",
    "    if time_elements[0].hour >= 12 and time_elements[1].hour < 12:\n",
    "        # If the first time is in the evening and the last time is in the morning, we assume the last time is on the next day\n",
    "        datetimes[1] = datetimes[1] + timedelta(days=1)\n",
    "\n",
    "    # Check if we have exactly two time elements (start and stop time)\n",
    "    if len(time_elements) != 2:\n",
    "        raise ValueError(f\"Found {len(time_elements)} time elements, expected exactly two (i.e. start and stop time).\")\n",
    "    \n",
    "    return datetimes\n",
    "\n",
    "# Test the functions thusfar\n",
    "_, soups = load_and_parse_html_files('html')\n",
    "for soup in soups:\n",
    "    start_time, end_time = find_begin_and_end_timestamps(soup)\n",
    "    print(f\"Start time: {start_time.time()}, End time: {end_time.time()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "727f13dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2022-04-09 23:51:00, End time: 2022-04-10 08:24:00, Time delta: 8:33:00\n",
      "[datetime.datetime(2022, 4, 9, 23, 51), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 9, 23, 59), 'Deep Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 0, 45), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 0, 58), 'Deep Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 1, 15), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 1, 24), 'Deep Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 1, 32), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 1, 49), 'REM Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 2, 8), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 2, 22), 'REM Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 2, 23), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 2, 24), 'REM Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 2, 25), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 3, 49), 'Deep Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 4, 1), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 4, 16), 'REM Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 5, 10), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 6, 16), 'Unmeasurable']\n",
      "[datetime.datetime(2022, 4, 10, 6, 36), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 6, 47), 'REM Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 7, 1), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 7, 34), 'Deep Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 7, 44), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 7, 45), 'Awake']\n",
      "[datetime.datetime(2022, 4, 10, 7, 46), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 8, 1), 'REM Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 8, 13), 'Light Sleep']\n",
      "[datetime.datetime(2022, 4, 10, 8, 24), 'End of Sleep']\n"
     ]
    }
   ],
   "source": [
    "def get_timestamps_for_each_sleepcycle(soup, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Get the timestamps for each sleep cycle from the parsed HTML soups. This is done by assessing the relative locations of the coloured rectangles in the graph. Returns start times each sleep cycle with corresponding sleep cycle label.\n",
    "    Args:\n",
    "        soup: The BeautifulSoup object containing the HTML content.\n",
    "        start_time: datetime.time: The start time of the sleep.\n",
    "        end_time: datetime.time: The end time of the sleep.\n",
    "    Returns:\n",
    "        list: A list of lists, each containing the start time of a sleep cycle and the corresponding sleep cycle label.\n",
    "    \"\"\"\n",
    "    # The width of the graph is used to calculate the relative positions of the sleep cycles (as it is equal to the relative end time).\n",
    "    # A <rect> element with class=\"highcharts-plot-background\" and \"fill=none\" holds the width of the graph in a width attribute.\n",
    "    graph_width = float(soup.find(\"rect\", class_=\"highcharts-plot-background\", fill=\"none\").get(\"width\"))\n",
    "\n",
    "    # The rectangles of a graph are <g> elements, each with multiple <path> elements inside.\n",
    "    # Finding those <g> elements using class names such as: [\"\"highcharts-series highcharts-series-0 highcharts-area-series\", \"highcharts-series highcharts-series-1 highcharts-area-series\"]\n",
    "    pattern = re.compile(r\"highcharts-series highcharts-series-\\d+ highcharts-area-series\")\n",
    "    rectangles = soup.find_all(\"g\", class_=pattern)\n",
    "    if not rectangles:\n",
    "        raise ValueError(\"No rectangles found in the graph. Please check the HTML structure or class names.\")\n",
    "    \n",
    "    # Each of these <g> elements, in its first child element (a <path> element) the \"d\" attribute contains the coordinates of the rectangle in the graph. The number after the first L is the starting x coordinate of the rectangle (and thus the start time of that sleep cycle).\n",
    "    # Moreover, the colour (fill) of the first child element (a <path> element) indicates the type of sleep cycle (e.g. #3b97f3 = light, #1976d2 = deep, #d42fc2 = REM, #e55ecb = Awake, transparant = Unmeasurable).\n",
    "    sleep_labels = {\n",
    "        \"#3b97f3\": \"Light Sleep\",\n",
    "        \"#1976d2\": \"Deep Sleep\",\n",
    "        \"#d42fc2\": \"REM Sleep\",\n",
    "        \"#e55ecb\": \"Awake\",\n",
    "        \"transparent\": \"Unmeasurable\"\n",
    "    }\n",
    "\n",
    "    sleep_cycles = []\n",
    "    for rectangle in rectangles:\n",
    "        path = rectangle.find(\"path\")  # Contains the coordinates and fill colour of the rectangle\n",
    "\n",
    "        sleep_cycle_label = sleep_labels[path.get(\"fill\")]  # Convert colour to label\n",
    "\n",
    "        # The \"d\" attribute contains the coordinates of the rectangle\n",
    "        tokens = path.get(\"d\").split()  # Extract the x coordinates from the \"d\" attribute, by first splitting the string into tokens\n",
    "        # Find the first occurance of \"L\", the number (now token) after it contains start coordinate\n",
    "        start_coordinate = float(tokens[tokens.index('L') + 1])\n",
    "\n",
    "        sleep_cycles.append([start_coordinate, sleep_cycle_label])\n",
    "\n",
    "    # Convert the relative start to absolute times, by first normalizing the start times (0 to 1) based on the graph width\n",
    "    sleep_cycles = [[sleep_cycle[0]/graph_width, sleep_cycle[1]] for sleep_cycle in sleep_cycles]\n",
    "    timedelta = end_time - start_time  # Absolute time difference between start and end time\n",
    "    # Add the weighted timedelta to the start time \n",
    "    sleep_cycles = [[(start_time + timedelta * sleep_cycle[0]), sleep_cycle[1]] for sleep_cycle in sleep_cycles]\n",
    "\n",
    "    sleep_cycles.append([end_time, \"End of Sleep\"])  # Append the end time of the sleep\n",
    "\n",
    "    return sleep_cycles\n",
    "\n",
    "# Test the functions\n",
    "for soup in soups[:1]: # Limit to first soup for testing\n",
    "    start_time, end_time = find_begin_and_end_timestamps(soup)\n",
    "    print(f\"Start time: {start_time}, End time: {end_time}, Time delta: {end_time - start_time}\")\n",
    "    sleep_cycles = get_timestamps_for_each_sleepcycle(soup, start_time, end_time)\n",
    "\n",
    "    for sleep_cycle in sleep_cycles:\n",
    "        print(sleep_cycle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fc4bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sleep cycles to a CSV file\n",
    "def save_sleep_cycles_to_csv(sleep_cycles, output_file, directory='csv'):\n",
    "    \"\"\"\n",
    "    Save the sleep cycles to a CSV file.\n",
    "    Args:\n",
    "        sleep_cycles (list): A list of tuples containing the start timestamps and corresponding label of each sleep cycle.\n",
    "        output_file (str): The path to the output CSV file.\n",
    "        directory (str): The directory where the CSV file will be saved (default is 'csv').\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(directory, output_file)\n",
    "    os.makedirs(directory, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Start Time', 'Sleep Cycle'])  # Write header\n",
    "        for sleep_cycle in sleep_cycles:\n",
    "            writer.writerow([sleep_cycle[0], sleep_cycle[1]])\n",
    "    print(f\"Saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14098cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 HTML files in directory: html\n",
      "Processed file: html\\09_04_2025.html\n",
      "Processed file: html\\10_04_2025.html\n",
      "Processed file: html\\13_04_2025.html\n",
      "Start time: 2022-04-09 23:51:00, End time: 2022-04-10 08:24:00, Time delta: 8:33:00\n",
      "Saved to csv\\09_04_2025.csv\n",
      "Start time: 2022-04-10 00:33:00, End time: 2022-04-10 08:24:00, Time delta: 7:51:00\n",
      "Saved to csv\\10_04_2025.csv\n",
      "Start time: 2022-04-13 22:29:00, End time: 2022-04-14 07:42:00, Time delta: 9:13:00\n",
      "Saved to csv\\13_04_2025.csv\n"
     ]
    }
   ],
   "source": [
    "# The full thing\n",
    "file_names, soups = load_and_parse_html_files('html')\n",
    "for soup, file_name in zip(soups, file_names):\n",
    "    start_time, end_time = find_begin_and_end_timestamps(soup)\n",
    "    print(f\"Start time: {start_time}, End time: {end_time}, Time delta: {end_time - start_time}\")\n",
    "    sleep_cycles = get_timestamps_for_each_sleepcycle(soup, start_time, end_time)\n",
    "    save_sleep_cycles_to_csv(sleep_cycles, os.path.basename(file_name).replace('.html', '.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
